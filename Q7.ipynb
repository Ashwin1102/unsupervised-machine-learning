{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-13 17:51:48.629213: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-13 17:51:49.004688: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-13 17:51:49.007790: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-13 17:52:06.719739: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "X = np.concatenate((X_train, X_test), axis=0)\n",
    "y = np.concatenate((y_train, y_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.reshape(70000, 784)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ind = np.array([])\n",
    "\n",
    "for l in range(10):\n",
    "    sample_ind = np.concatenate((sample_ind, np.where(y == l)[0][:500]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ind = sample_ind.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_x = X[sample_ind]\n",
    "sample_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(sample_x)\n",
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distances(mat):\n",
    "    from tqdm import tqdm\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    if isinstance(mat, (pd.DataFrame, pd.Series)):\n",
    "        mat = mat.to_numpy()\n",
    "\n",
    "    dot_product = np.dot(mat, mat.T)\n",
    "    xi2 = np.sum(mat**2, axis=1)\n",
    "    n = len(xi2)\n",
    "    distances = np.zeros((n, n))\n",
    "\n",
    "    for i in tqdm(range(n)):\n",
    "        for j in range(n):\n",
    "            distances[i, j] = np.sqrt(max(xi2[i] + xi2[j] - (2 * dot_product[i, j]), 0))\n",
    "\n",
    "    return distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Given a single point from the dataframe, this function will traverse all the neigbhours \n",
    " of the given node (until it cannot find new unique neigbhours). '''\n",
    " \n",
    "from tqdm import tqdm\n",
    "\n",
    "def dfs(df, node_id, visited, current_cluster):\n",
    "    stack = [node_id]\n",
    "    \n",
    "    with tqdm(total=len(df), desc=\"DFS Progress\") as pbar:\n",
    "        while len(stack) != 0:\n",
    "            node_id = stack.pop()\n",
    "            df.at[node_id, 'cluster'] = current_cluster\n",
    "            \n",
    "            if visited[node_id]:\n",
    "                continue\n",
    "            \n",
    "            visited[node_id] = 1\n",
    "            neigbhours = [int(i) for i in df['neighbors'][node_id].split(',')]\n",
    "\n",
    "            for neigbhour in neigbhours:\n",
    "                stack.append(neigbhour)\n",
    "\n",
    "            pbar.update(1) \n",
    "\n",
    "    return df\n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def create_neighbors(ep, df):\n",
    "    dist_matrix = euclidean_distances(df)  \n",
    "\n",
    "    n = dist_matrix.shape[0]\n",
    "\n",
    "    neighbors = []\n",
    "\n",
    "    # Using tqdm to track progress of the loop\n",
    "    for i in tqdm(range(n), desc=\"Processing Neighbors\", unit=\"point\"):\n",
    "        current_neighbors = np.where(dist_matrix[i] < ep)[0]  \n",
    "        current_neighbors = \",\".join(map(str, current_neighbors.tolist()))  \n",
    "        if len(current_neighbors) == 0:\n",
    "             current_neighbors = str(i)\n",
    "        neighbors.append(current_neighbors) \n",
    "\n",
    "    return np.array(neighbors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def dbscan(ep, minpts, df):\n",
    "    n = df.shape[0]\n",
    "    neighbors = create_neighbors(ep, df)\n",
    "    \n",
    "    df1 = df.copy()\n",
    "    df1['neighbors'] = neighbors\n",
    "    df1['cluster'] = np.array([0] * n)\n",
    "\n",
    "    curr_cluster = 1\n",
    "\n",
    "    with tqdm(total=n, desc=\"DBSCAN Progress\") as pbar:\n",
    "        for pt in range(n):\n",
    "            curr_pt = pt\n",
    "\n",
    "            if df1.at[curr_pt, 'cluster'] != 0:\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "            \n",
    "            neigbhours = [int(i) for i in df1['neighbors'][curr_pt].split(',')]\n",
    "\n",
    "            if len(neigbhours) >= minpts:\n",
    "                df1 = dfs(df1.copy(), curr_pt, np.array([0] * n), curr_cluster)\n",
    "                curr_cluster += 1\n",
    "            else:\n",
    "                for neigbhour in neigbhours:\n",
    "                    if len(neigbhours) >= minpts:\n",
    "                        df1 = dfs(df1.copy(), curr_pt, np.array([0] * n), curr_cluster)\n",
    "                        curr_cluster += 1 \n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    return df1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN Fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2) \n",
    "X_pca = pca.fit_transform(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = pd.DataFrame(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:43<00:00, 115.09it/s]\n",
      "Processing Neighbors: 100%|██████████| 5000/5000 [00:00<00:00, 92236.43point/s]\n",
      "DFS Progress:   0%|          | 4/5000 [00:00<00:01, 4527.04it/s]\n",
      "DFS Progress:   0%|          | 5/5000 [00:00<00:01, 4729.71it/s]\n",
      "DFS Progress:   0%|          | 5/5000 [00:00<00:00, 5315.97it/s]\n",
      "DFS Progress:   0%|          | 4/5000 [00:00<00:01, 4682.45it/s]\n",
      "DFS Progress:   0%|          | 7/5000 [00:00<00:00, 5819.65it/s]\n",
      "DFS Progress:   0%|          | 5/5000 [00:00<00:00, 5123.75it/s]\n",
      "DFS Progress:   0%|          | 5/5000 [00:00<00:00, 5108.77it/s]\n",
      "DFS Progress:   0%|          | 4/5000 [00:00<00:01, 3773.55it/s]\n",
      "DFS Progress:   0%|          | 5/5000 [00:00<00:01, 4441.24it/s]\n",
      "DFS Progress:   0%|          | 5/5000 [00:00<00:01, 4545.19it/s]68it/s]\n",
      "DBSCAN Progress: 100%|██████████| 5000/5000 [00:00<00:00, 39847.01it/s]\n"
     ]
    }
   ],
   "source": [
    "df2 = df.copy()\n",
    "df2 = dbscan(8, 4, X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>neighbors</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1413.172416</td>\n",
       "      <td>-431.196167</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-703.493467</td>\n",
       "      <td>-1123.301283</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>831.186554</td>\n",
       "      <td>-1184.010088</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>998.676650</td>\n",
       "      <td>-850.216681</td>\n",
       "      <td>3,1889</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1302.288306</td>\n",
       "      <td>-828.127455</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>-894.665635</td>\n",
       "      <td>1595.566640</td>\n",
       "      <td>4995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>96.251509</td>\n",
       "      <td>1072.076267</td>\n",
       "      <td>4996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>-991.786203</td>\n",
       "      <td>1380.728076</td>\n",
       "      <td>4997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>-504.438955</td>\n",
       "      <td>1656.264722</td>\n",
       "      <td>4998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>-1103.608776</td>\n",
       "      <td>1091.689750</td>\n",
       "      <td>4999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1 neighbors  cluster\n",
       "0     1413.172416  -431.196167         0        0\n",
       "1     -703.493467 -1123.301283         1        0\n",
       "2      831.186554 -1184.010088         2        0\n",
       "3      998.676650  -850.216681    3,1889        0\n",
       "4     1302.288306  -828.127455         4        0\n",
       "...           ...          ...       ...      ...\n",
       "4995  -894.665635  1595.566640      4995        0\n",
       "4996    96.251509  1072.076267      4996        0\n",
       "4997  -991.786203  1380.728076      4997        0\n",
       "4998  -504.438955  1656.264722      4998        0\n",
       "4999 -1103.608776  1091.689750      4999        0\n",
       "\n",
       "[5000 rows x 4 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  5,  2,  3,  4,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df2['cluster'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "score = silhouette_score(X_pca, labels, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster\n",
       "0     4951\n",
       "5        7\n",
       "2        5\n",
       "3        5\n",
       "6        5\n",
       "7        5\n",
       "9        5\n",
       "10       5\n",
       "1        4\n",
       "4        4\n",
       "8        4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.411636906409945"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN 20NG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_20ng_and_convert(file_path = '20ng.csv'):\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    import pandas as pd\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['index'] = df['index'].str.replace(r'\\d+$', '', regex=True)\n",
    "    classes = [\"alt.atheism\", \"sci.med\", \"sci.electronics\", \"comp.graphics\", \"talk.politics.guns\", \"sci.crypt\"]\n",
    "    df = df[df['index'].isin(classes)]\n",
    "    vectorizer = TfidfVectorizer(use_idf=False)\n",
    "    # vectorizer = TfidfVectorizer(use_idf=False)\n",
    "    sparse_matrix = vectorizer.fit_transform(df['content'])\n",
    "    sparse_df = pd.DataFrame.sparse.from_spmatrix(sparse_matrix, columns=vectorizer.get_feature_names_out())\n",
    "    sparse_df_mean = sparse_df.mean(axis=0)\n",
    "    sparse_std_sub = sparse_df.sparse.to_dense().std(axis=0)\n",
    "    sparse_df = (sparse_df - sparse_df_mean)/sparse_std_sub\n",
    "    sparse_df['index'] = df['index'].to_numpy()\n",
    "    return sparse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_20ng = read_20ng_and_convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_20ng_x = df_20ng.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_20ng_x_without = df_20ng_x.drop(['cluster', 'neighbors'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6000/6000 [01:03<00:00, 94.05it/s] \n",
      "Processing Neighbors: 100%|██████████| 6000/6000 [00:00<00:00, 33130.41point/s]\n",
      "DFS Progress:   0%|          | 2/6000 [00:00<00:01, 4134.36it/s]\n",
      "DFS Progress:   0%|          | 2/6000 [00:00<00:01, 4375.90it/s]it/s]\n",
      "DFS Progress:   0%|          | 2/6000 [00:00<00:01, 4277.72it/s]it/s]\n",
      "DFS Progress:   0%|          | 2/6000 [00:00<00:06, 979.29it/s]9it/s]\n",
      "DFS Progress:   0%|          | 2/6000 [00:00<00:01, 4038.81it/s]it/s]\n",
      "DFS Progress:   0%|          | 2/6000 [00:00<00:01, 4282.09it/s]it/s]\n",
      "DFS Progress:   0%|          | 2/6000 [00:00<00:01, 4382.76it/s]t/s] \n",
      "DBSCAN Progress: 100%|██████████| 6000/6000 [00:14<00:00, 408.02it/s]\n"
     ]
    }
   ],
   "source": [
    "df_20ng_x_without1 = df_20ng_x_without.copy()\n",
    "df_20ng_x_without1 = dbscan(10, 2, df_20ng_x_without1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_20ng_x_without1['cluster'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df_20ng_x_without1['cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "df_20ng_x_without_sl = df_20ng_x_without.to_numpy() \n",
    "score = silhouette_score(df_20ng_x_without_sl, labels, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.18244887952253033"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN Households"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ucimlrepo\n",
      "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /home/khairnar.as/.conda/envs/myenv/lib/python3.8/site-packages (from ucimlrepo) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in /home/khairnar.as/.conda/envs/myenv/lib/python3.8/site-packages (from ucimlrepo) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/khairnar.as/.conda/envs/myenv/lib/python3.8/site-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/khairnar.as/.conda/envs/myenv/lib/python3.8/site-packages (from pandas>=1.0.0->ucimlrepo) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/khairnar.as/.conda/envs/myenv/lib/python3.8/site-packages (from pandas>=1.0.0->ucimlrepo) (2024.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /home/khairnar.as/.conda/envs/myenv/lib/python3.8/site-packages (from pandas>=1.0.0->ucimlrepo) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/khairnar.as/.conda/envs/myenv/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n",
      "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
      "Installing collected packages: ucimlrepo\n",
      "Successfully installed ucimlrepo-0.0.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khairnar.as/.conda/envs/myenv/lib/python3.8/site-packages/ucimlrepo/fetch.py:97: DtypeWarning: Columns (2,3,4,5,6,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_url)\n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "individual_household_electric_power_consumption = fetch_ucirepo(id=235) \n",
    "X = individual_household_electric_power_consumption.data.features \n",
    "y = individual_household_electric_power_consumption.data.targets \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(['Date', 'Time'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Global_active_power          0\n",
       "Global_reactive_power        0\n",
       "Voltage                      0\n",
       "Global_intensity             0\n",
       "Sub_metering_1               0\n",
       "Sub_metering_2               0\n",
       "Sub_metering_3           25979\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random_numbers = random.sample(range(1, 200000), 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub = X.iloc[random_numbers, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "db = DBSCAN(eps=3.05, min_samples=5)  # Adjust eps & min_samples as needed\n",
    "labels = db.fit_predict(X_sub)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5000 entries, 138677 to 37641\n",
      "Data columns (total 7 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Global_active_power    5000 non-null   float64\n",
      " 1   Global_reactive_power  5000 non-null   float64\n",
      " 2   Voltage                5000 non-null   float64\n",
      " 3   Global_intensity       5000 non-null   float64\n",
      " 4   Sub_metering_1         5000 non-null   float64\n",
      " 5   Sub_metering_2         5000 non-null   float64\n",
      " 6   Sub_metering_3         5000 non-null   float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 312.5 KB\n"
     ]
    }
   ],
   "source": [
    "X_sub1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub = X_sub.apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub = X_sub.reset_index()\n",
    "# X_sub.drop('index', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub.drop('level_0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.372</td>\n",
       "      <td>0.058</td>\n",
       "      <td>243.46</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.474</td>\n",
       "      <td>0.170</td>\n",
       "      <td>244.44</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.344</td>\n",
       "      <td>0.184</td>\n",
       "      <td>243.10</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.360</td>\n",
       "      <td>0.086</td>\n",
       "      <td>240.14</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.294</td>\n",
       "      <td>0.090</td>\n",
       "      <td>241.94</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>4.174</td>\n",
       "      <td>0.086</td>\n",
       "      <td>233.68</td>\n",
       "      <td>17.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>3.964</td>\n",
       "      <td>0.306</td>\n",
       "      <td>234.66</td>\n",
       "      <td>16.8</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>2.364</td>\n",
       "      <td>0.000</td>\n",
       "      <td>244.86</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0.296</td>\n",
       "      <td>0.108</td>\n",
       "      <td>241.61</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>3.354</td>\n",
       "      <td>0.330</td>\n",
       "      <td>235.07</td>\n",
       "      <td>14.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Global_active_power  Global_reactive_power  Voltage  Global_intensity  \\\n",
       "0                   1.372                  0.058   243.46               5.6   \n",
       "1                   0.474                  0.170   244.44               2.0   \n",
       "2                   0.344                  0.184   243.10               1.6   \n",
       "3                   1.360                  0.086   240.14               5.6   \n",
       "4                   0.294                  0.090   241.94               1.2   \n",
       "...                   ...                    ...      ...               ...   \n",
       "4995                4.174                  0.086   233.68              17.8   \n",
       "4996                3.964                  0.306   234.66              16.8   \n",
       "4997                2.364                  0.000   244.86               9.6   \n",
       "4998                0.296                  0.108   241.61               1.2   \n",
       "4999                3.354                  0.330   235.07              14.4   \n",
       "\n",
       "      Sub_metering_1  Sub_metering_2  Sub_metering_3  \n",
       "0                0.0             0.0            18.0  \n",
       "1                0.0             0.0             0.0  \n",
       "2                0.0             0.0             0.0  \n",
       "3                0.0             1.0            18.0  \n",
       "4                0.0             0.0             0.0  \n",
       "...              ...             ...             ...  \n",
       "4995             0.0            37.0            17.0  \n",
       "4996            38.0             0.0            16.0  \n",
       "4997             0.0             0.0             0.0  \n",
       "4998             0.0             1.0             0.0  \n",
       "4999             0.0             2.0            17.0  \n",
       "\n",
       "[5000 rows x 7 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:39<00:00, 127.42it/s]\n",
      "Processing Neighbors: 100%|██████████| 5000/5000 [00:00<00:00, 6766.23point/s]\n",
      "DFS Progress:  33%|███▎      | 1631/5000 [00:11<00:23, 141.98it/s]\n",
      "DFS Progress:  60%|██████    | 3008/5000 [00:56<00:37, 53.22it/s]it]\n",
      "DFS Progress:   1%|          | 28/5000 [00:00<00:00, 5281.07it/s]it]\n",
      "DFS Progress:   2%|▏         | 86/5000 [00:00<00:01, 2980.19it/s]\n",
      "DFS Progress:   1%|          | 51/5000 [00:00<00:01, 3710.74it/s]\n",
      "DFS Progress:   1%|          | 31/5000 [00:00<00:01, 4427.38it/s]\n",
      "DFS Progress:   0%|          | 7/5000 [00:00<00:00, 5933.74it/s]\n",
      "DFS Progress:   0%|          | 8/5000 [00:00<00:00, 6637.87it/s]\n",
      "DFS Progress:   0%|          | 6/5000 [00:00<00:00, 6297.75it/s]\n",
      "DFS Progress:   0%|          | 7/5000 [00:00<00:00, 6645.57it/s]/s] \n",
      "DFS Progress:   0%|          | 7/5000 [00:00<00:00, 6896.91it/s]\n",
      "DBSCAN Progress: 100%|██████████| 5000/5000 [01:08<00:00, 73.36it/s]\n"
     ]
    }
   ],
   "source": [
    "X_sub1 = X_sub.copy()\n",
    "X_sub1 = dbscan(3.05, 5, X_sub1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = X_sub1['cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "score = silhouette_score(X_sub, labels, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6722807221147779"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works well on household data due to its low dimensionality. This makes the data much dense and also creates the proper gap between the clusters. Whereas on the other side, in MNIST and 20NG which have high number of dimensions (784 and 50000+) this makes more uniform and hence less dense. The other reason for low performance on MNIST and 20NG is that its high dimensionality creates overlapping clusters which makes the DBSCAN much harder to classify the clusters. \n",
    "\n",
    "DBSCAN works well for specific values of epsilon and minpts because as data becomes more dense we need to decrease the minpts value (as more data will come in small area, this is for given epsilon value)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
