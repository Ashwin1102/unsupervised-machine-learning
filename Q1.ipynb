{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) prove that E step update on membership (\\pi) achieves the minimum objective given the current centroids( \\mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We know that objective function will have the minimum value as 0 because it has squared difference term in it which will never be negative. Now the equation will be zero when all the data points will equal to the mu values that all data points are the clusters. This proves that e steps tries to minimize the distance between centriod and data points minimizing the objective function. Also we know as the k value increases the objective value will become less as the each data point will more options for clusters\n",
    "\n",
    "$$\n",
    "J = \\sum_{i=1}^{N} ||x - \\mu_k||^2 . \\pi_{ik}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B) prove that M step update on centroids (\\mu) achieves the minimum objective given the current memberships( \\pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know that minimum objective will be achieved when mu is average of all the members. Therefore, let's take the objective function and differentiate it with mu_k.\n",
    "\n",
    "The objective function of K-Means clustering is:\n",
    "\n",
    "$$\n",
    "J = \\sum_{i=1}^{N} ||x - \\mu_k||^2 . \\pi_{ik}\n",
    "$$\n",
    "\n",
    "Now differentiating this with $ \\mu_k $ we get,\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial \\mu_k} = \\sum_{i=1}^{N} \\pi_{ik} \\cdot \\frac{\\partial}{\\partial \\mu_k} ||x_i - \\mu_k||^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\sum_{i=1}^{N} 2.(\\mu_k - x_i) \\pi_{ik}                                            \n",
    "$$\n",
    "\n",
    "As we want to minimize it so we will equate it to 0,\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial \\mu_k} = 0\n",
    "$$\n",
    "\n",
    "Therefore,\n",
    "$$\n",
    "\\sum_{i=1}^{N} 2.(\\mu_k - x_i) \\pi_{ik}   = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{N} \\mu_k . \\pi_{ik} - \\sum_{i=1}^{N} x_i .\\pi_{ik}   = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{N} \\mu_k . \\pi_{ik}  = \\sum_{i=1}^{N} x_i .\\pi_{ik}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mu_k = \\frac{\\sum_{i=1}^{N} x_i .\\pi_{ik}}{\\sum_{i=1}^{N}\\pi_{ik}}\n",
    "$$\n",
    "\n",
    "So, we can observe that it is the weighted sum of x values where $\\pi$ acts as weights. For hard kmeans these will be binary matrix with 1s and 0s, where for soft kmeans it is array with probabilities in a row summing to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C) Explain why KMeans has to stop (converge), but not necessarily to the global minimum objective value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the objective function is monotonically decreasing, and at every iteration kmeans tries to minimize the distance between data points and the centroids. When we get the optimal centroids, changing them (in any direction) after this will increase the distance between the data and centriod leading to higher objective function. So the nature of the objective (that is decreasing till one point and increasing after it) shows that the model will converge to the minima. \n",
    "\n",
    "Kmeans might not necessarly converge to global minima. Suppose there are 2 actual clusters in the data, and while random intialization we take two centroids in the same one cluster. In this case, the objective function will minimize, but it will try to minimize for that same cluster. In this case, we will get the both centroids as the same which is not actually the case. The expected scenario would be two centroids in different clusters.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
